# Phase 1.4: LRU Compile Cache & Snapshot Patching - Research

**Researched:** 2026-02-11
**Domain:** Internal caching architecture, immutable data structures, in-memory patching
**Confidence:** HIGH

## Summary

Phase 1.4 replaces the current single-snapshot compile cache (`self._compile_snapshot: CompileSnapshot | None`) with a multi-entry LRU cache keyed by `head_hash`, and upgrades EDIT/annotate handling from full cache invalidation to surgical in-memory snapshot patching. This is a purely internal refactor -- no new external dependencies, no schema changes, no public API changes.

The current implementation (built in Phase 1.1) stores exactly one `CompileSnapshot` at a time. When HEAD changes (e.g., checkout, reset, branch switch in future phases), the snapshot is either stale or invalidated. EDIT and annotate operations force full cache invalidation and recompile from DB. Phase 1.4 addresses both limitations: LRU cache retains multiple snapshots so previously-compiled positions are cache hits, and snapshot patching replaces the EDIT target's message in-memory without DB re-reads.

The standard approach is an `OrderedDict`-based LRU cache (no external dependencies) combined with `dataclasses.replace()` for immutable snapshot patching. A `verify_cache` debug flag enables oracle testing where every patched result is cross-checked against a full recompile.

**Primary recommendation:** Use `collections.OrderedDict` for the LRU cache (O(1) get/put/evict, stdlib, well-understood) and `dataclasses.replace()` for creating patched snapshot copies. Keep `CompileSnapshot` frozen. Test every cache path with oracle assertions (patched == full recompile).

## Standard Stack

This phase requires no new libraries. All implementation uses Python stdlib.

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| `collections.OrderedDict` | stdlib | LRU cache backing store | O(1) `move_to_end()`, O(1) `popitem(last=False)` for eviction. No dependency. The standard Python LRU cache pattern. |
| `dataclasses.replace()` | stdlib | Frozen dataclass copy-with-modification | Creates new `CompileSnapshot` with specific fields replaced. Shallow copy, O(1) for our use case. The idiomatic Python pattern for frozen dataclass mutation. |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| `copy.deepcopy` | stdlib | Deep copy of mutable nested structures | Only if snapshot contains mutable nested data (e.g., `generation_configs` dicts). Current `CompileSnapshot` uses tuples (immutable) so `replace()` alone suffices for most fields. |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| OrderedDict LRU | `functools.lru_cache` | `lru_cache` is for decorating pure functions. Cannot be used on instance methods without memory leak risk (retains `self` reference). Not suitable for manual cache management where we need explicit invalidation and patching. |
| OrderedDict LRU | `cachetools.LRUCache` | External dependency for minimal benefit. OrderedDict does everything we need. |
| `dataclasses.replace()` | Manual `CompileSnapshot(...)` construction | `replace()` is cleaner, less error-prone, and explicitly communicates "copy with modifications." |

**Installation:** None required (all stdlib).

## Architecture Patterns

### Current State (What Exists)

```python
# In Tract.__init__():
self._compile_snapshot: CompileSnapshot | None = None

# In Tract.compile():
if self._compile_snapshot is not None and self._compile_snapshot.head_hash == current_head:
    return self._snapshot_to_compiled(self._compile_snapshot)  # Cache hit

# In Tract.commit() for APPEND:
self._extend_snapshot_for_append(info)  # O(1) incremental

# In Tract.commit() for EDIT, Tract.annotate(), Tract.batch():
self._compile_snapshot = None  # Full invalidation
```

### Target State (Phase 1.4)

```python
# In Tract.__init__():
self._snapshot_cache: OrderedDict[str, CompileSnapshot] = OrderedDict()
self._snapshot_cache_maxsize: int = 8  # Configurable

# In Tract.compile():
# 1. Check LRU cache by head_hash
if current_head in self._snapshot_cache:
    self._snapshot_cache.move_to_end(current_head)  # Mark as recently used
    return self._snapshot_to_compiled(self._snapshot_cache[current_head])

# 2. Cache miss: full compile, store in LRU
result = self._compiler.compile(...)
snapshot = self._build_snapshot_from_compiled(current_head, result)
self._cache_put(current_head, snapshot)
return result

# In Tract.commit() for EDIT:
# Snapshot patching instead of invalidation
patched = self._patch_snapshot_for_edit(current_snapshot, edit_info)
self._cache_put(patched.head_hash, patched)

# In Tract.annotate():
# Snapshot patching for priority change
patched = self._patch_snapshot_for_annotate(current_snapshot, target_hash, new_priority)
self._cache_put(patched.head_hash, patched)
```

### Recommended Project Structure (No New Files)

All changes are within existing files:

```
src/tract/
    protocols.py          # CompileSnapshot unchanged (already frozen, already has needed fields)
    tract.py              # LRU cache replaces single snapshot; add patching methods
tests/
    test_tract.py         # New tests for LRU + patching + oracle verification
```

### Pattern 1: OrderedDict-Based LRU Cache

**What:** A fixed-capacity cache that evicts least-recently-used entries when full.
**When to use:** When you need O(1) get/put with bounded memory and access-order tracking.
**Example:**

```python
from collections import OrderedDict
from dataclasses import replace

class Tract:
    def __init__(self, ...):
        self._snapshot_cache: OrderedDict[str, CompileSnapshot] = OrderedDict()
        self._snapshot_cache_maxsize: int = 8

    def _cache_get(self, head_hash: str) -> CompileSnapshot | None:
        """Get snapshot from LRU cache. Returns None on miss."""
        if head_hash not in self._snapshot_cache:
            return None
        self._snapshot_cache.move_to_end(head_hash)  # Mark as recently used
        return self._snapshot_cache[head_hash]

    def _cache_put(self, head_hash: str, snapshot: CompileSnapshot) -> None:
        """Store snapshot in LRU cache, evicting LRU entry if at capacity."""
        if head_hash in self._snapshot_cache:
            self._snapshot_cache.move_to_end(head_hash)
        self._snapshot_cache[head_hash] = snapshot
        while len(self._snapshot_cache) > self._snapshot_cache_maxsize:
            self._snapshot_cache.popitem(last=False)  # Evict LRU

    def _cache_remove(self, head_hash: str) -> None:
        """Remove a specific entry from cache."""
        self._snapshot_cache.pop(head_hash, None)

    def _cache_clear(self) -> None:
        """Clear all cached snapshots."""
        self._snapshot_cache.clear()
```

### Pattern 2: Snapshot Patching for EDIT Commits

**What:** When an EDIT commit replaces one message in the compiled output, patch the cached snapshot in-memory instead of recompiling from DB.
**When to use:** EDIT commits where the target commit is in the cached snapshot's effective commit list.
**Key insight:** An EDIT commit targets a specific original commit (via `response_to`). The snapshot contains the compiled message list. We find the message corresponding to the edited commit, replace it with the new message, re-aggregate, and recount tokens.

**Example:**

```python
def _patch_snapshot_for_edit(
    self,
    snapshot: CompileSnapshot,
    new_head_hash: str,
    edit_commit_row: CommitRow,
) -> CompileSnapshot:
    """Patch a cached snapshot for an EDIT commit.

    Instead of full invalidation + recompile:
    1. Find the message in raw_messages that corresponds to the edited target
    2. Replace it with the new message built from the edit commit's content
    3. Re-aggregate and recount tokens
    4. Return a new snapshot with the updated head_hash
    """
    assert isinstance(self._compiler, DefaultContextCompiler)

    target_hash = edit_commit_row.response_to
    new_message = self._compiler.build_message_for_commit(edit_commit_row)
    new_config = edit_commit_row.generation_config_json or {}

    # We need to know which position in raw_messages corresponds to the target
    # The snapshot needs to track commit_hash -> position mapping
    # This requires extending CompileSnapshot with a commit_hashes tuple
    # (ordered, parallel to raw_messages)

    # Find and replace in raw_messages
    new_raw = list(snapshot.raw_messages)
    new_configs = list(snapshot.generation_configs)
    patched = False
    for i, commit_hash in enumerate(snapshot.commit_hashes):
        if commit_hash == target_hash:
            new_raw[i] = new_message
            # For config: use edit's config if present, else keep original
            if edit_commit_row.generation_config_json is not None:
                new_configs[i] = new_config
            patched = True
            break

    if not patched:
        # Target not in snapshot (shouldn't happen but safety fallback)
        return None  # Signal to caller: do full recompile

    # Re-aggregate
    new_aggregated = self._compiler._aggregate_messages(new_raw)

    # Recount tokens
    messages_dicts = [
        {"role": m.role, "content": m.content}
        if m.name is None
        else {"role": m.role, "content": m.content, "name": m.name}
        for m in new_aggregated
    ]
    new_token_count = self._token_counter.count_messages(messages_dicts)

    return CompileSnapshot(
        head_hash=new_head_hash,
        raw_messages=tuple(new_raw),
        aggregated_messages=tuple(new_aggregated),
        effective_hashes=snapshot.effective_hashes | {new_head_hash},
        commit_count=snapshot.commit_count,  # Same count (edit replaces, doesn't add)
        token_count=new_token_count,
        token_source=self._tiktoken_source(),
        generation_configs=tuple(new_configs),
        commit_hashes=snapshot.commit_hashes,  # Same commit positions
    )
```

### Pattern 3: Snapshot Patching for Annotate (Priority Change)

**What:** When annotating a commit with SKIP, remove its message from the snapshot. When annotating with NORMAL/PINNED (un-skipping), we need to add it back.
**When to use:** `annotate()` calls that change whether a commit is included in compilation.
**Key insight:** Annotating with SKIP removes a commit from the effective list. Un-skipping adds one back. Both cases can be handled by patching the raw_messages list and re-aggregating. However, un-skipping requires the original message which may not be in the snapshot's raw list. Two approaches:

1. **Simple approach (recommended for Phase 1.4):** Only patch for SKIP annotations on commits currently in the snapshot. For un-skip (NORMAL/PINNED on a previously-SKIP commit), fall back to full recompile. SKIP is the common case for annotation changes during active use.
2. **Full approach (future):** Store all messages including skipped ones in the snapshot, with a separate skip mask.

**Example:**

```python
def _patch_snapshot_for_annotate(
    self,
    snapshot: CompileSnapshot,
    target_hash: str,
    new_priority: Priority,
) -> CompileSnapshot | None:
    """Patch a cached snapshot for an annotation change.

    For SKIP: remove the target commit's message from raw_messages.
    For NORMAL/PINNED on a previously-included commit: no change needed
        (it's already there).
    For NORMAL/PINNED on a previously-SKIP commit: return None (full recompile).
    """
    # Check if target is currently in the snapshot
    target_idx = None
    for i, commit_hash in enumerate(snapshot.commit_hashes):
        if commit_hash == target_hash:
            target_idx = i
            break

    if new_priority == Priority.SKIP:
        if target_idx is None:
            # Already not in snapshot (already skipped or not in chain)
            # Just update head_hash in case it changed
            return replace(snapshot, head_hash=snapshot.head_hash)

        # Remove from raw_messages and re-aggregate
        new_raw = list(snapshot.raw_messages)
        new_configs = list(snapshot.generation_configs)
        new_hashes = list(snapshot.commit_hashes)
        del new_raw[target_idx]
        del new_configs[target_idx]
        del new_hashes[target_idx]

        new_aggregated = self._compiler._aggregate_messages(new_raw)
        # ... recount tokens, return new snapshot

    else:
        if target_idx is not None:
            # Already included, priority change doesn't affect compilation
            return snapshot  # No change needed
        else:
            # Commit was skipped, now needs to be included
            # We don't have the message content cached
            return None  # Signal: full recompile
```

### Pattern 4: Oracle Testing (verify_cache Debug Flag)

**What:** A debug mode where every cache hit/patch result is verified against a full recompile to catch cache consistency bugs.
**When to use:** In tests and optionally in development/debug mode.
**Example:**

```python
class Tract:
    def __init__(self, ..., verify_cache: bool = False):
        self._verify_cache = verify_cache

    def compile(self, ...):
        # ... normal cache logic produces `cached_result`

        if self._verify_cache and cached_result is not None:
            # Full recompile as oracle
            fresh_result = self._compiler.compile(
                self._tract_id, current_head,
            )
            assert cached_result.messages == fresh_result.messages, (
                f"Cache mismatch! Cached {len(cached_result.messages)} msgs "
                f"vs fresh {len(fresh_result.messages)} msgs"
            )
            assert cached_result.token_count == fresh_result.token_count, (
                f"Token count mismatch! Cached {cached_result.token_count} "
                f"vs fresh {fresh_result.token_count}"
            )

        return cached_result
```

### Anti-Patterns to Avoid

- **Using `functools.lru_cache` on `compile()`:** The `lru_cache` decorator is designed for pure functions. Using it on instance methods causes memory leaks (retains `self` reference in global cache) and cannot handle manual invalidation/patching. Ruff rule B019 explicitly warns against this.
- **Mutating cached snapshots in-place:** `CompileSnapshot` is frozen for good reason. Always use `dataclasses.replace()` or construct a new instance. In-place mutation of tuples within the snapshot is impossible (they're tuples), but beware of mutable `dict` references in `generation_configs`.
- **Storing mutable objects in the cache without copying:** The existing copy-on-output and copy-on-input patterns (established in Phase 1.3) must be preserved. When building snapshots, `generation_configs` must be deep-copied to prevent external mutation from corrupting cached data.
- **Unbounded cache growth:** Without a maxsize, the cache grows indefinitely. Even though context windows are bounded, long-running agents that checkout many different commits could accumulate many cached snapshots. Always enforce a maxsize.

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| LRU eviction | Custom doubly-linked list | `OrderedDict.move_to_end()` + `popitem(last=False)` | OrderedDict is C-optimized in CPython. A hand-rolled linked list is slower and buggier. |
| Frozen dataclass copy | Manual field-by-field construction | `dataclasses.replace(snapshot, field=new_value)` | `replace()` is less error-prone (won't miss fields), more readable, and explicitly communicates intent. |
| Message aggregation | Re-implementing aggregation in patching code | Reuse `DefaultContextCompiler._aggregate_messages()` | The aggregation logic already exists and is tested. Duplicating it creates divergence risk. |

**Key insight:** The core difficulty is not the LRU mechanism (that's trivial with OrderedDict). The core difficulty is (1) extending `CompileSnapshot` to track per-message commit hashes so patching knows which message to replace, and (2) ensuring the patched result is provably identical to a full recompile.

## Common Pitfalls

### Pitfall 1: CompileSnapshot Lacks Commit Hash Tracking

**What goes wrong:** The current `CompileSnapshot` stores `raw_messages` and `aggregated_messages` but does NOT store which commit hash produced which message. Without this mapping, EDIT patching cannot find the correct message to replace.
**Why it happens:** Phase 1.1 designed CompileSnapshot for APPEND-only extension, where you only ever add to the end. Patching requires random-access replacement by commit hash.
**How to avoid:** Add a `commit_hashes: tuple[str, ...]` field to `CompileSnapshot` that is parallel to `raw_messages`. Position `i` in `commit_hashes` corresponds to position `i` in `raw_messages`. Populate it during both full-compile snapshot building and incremental APPEND extension.
**Warning signs:** If you cannot write `_patch_snapshot_for_edit()` without a linear scan of DB-stored commits, the snapshot is missing information.

### Pitfall 2: LRU Cache Key Must Be the Snapshot's head_hash, Not Current HEAD

**What goes wrong:** Using `self.head` as the cache key seems natural but is wrong for EDIT/annotate patching. An EDIT commit creates a NEW commit (new head_hash) but the patched snapshot should be stored under this new hash. If you look up by the old head_hash, you'll get the pre-edit snapshot.
**Why it happens:** Confusion between "the head_hash at compile time" and "the head_hash at commit time."
**How to avoid:** When patching for EDIT:
1. Look up the PARENT snapshot (keyed by the pre-EDIT head_hash)
2. Patch it
3. Store the patched snapshot under the NEW head_hash (the EDIT commit's hash)
4. The old snapshot remains in the LRU cache (useful if user does `checkout` back)

### Pitfall 3: Aggregation Changes When Messages Are Removed or Replaced

**What goes wrong:** Removing a message (SKIP annotation) or replacing one (EDIT) can change aggregation boundaries. If commit B was between A and C, and A and C have the same role, removing B causes A and C to merge. The patching code must re-aggregate the entire raw message list, not just splice.
**Why it happens:** Same-role aggregation depends on the full sequence, not just local neighbors. Removing a message in the middle can create new same-role adjacencies.
**How to avoid:** After any patch that modifies `raw_messages`, always call `_aggregate_messages()` on the full list. Do NOT try to incrementally update aggregation -- the edge cases are subtle and the full re-aggregation is O(n) where n is the number of messages, which is small (bounded by context window).

### Pitfall 4: Generation Config Inheritance for EDIT Patching

**What goes wrong:** An EDIT commit may or may not carry its own `generation_config`. Per Phase 1.3 rules: "EDIT without generation_config preserves original commit's config." The patching code must implement this same logic.
**Why it happens:** The generation_config inheritance rule is implemented in `DefaultContextCompiler._build_effective_commits()` / step 4b. The patching code must replicate this logic.
**How to avoid:** When patching for EDIT:
- If `edit_commit.generation_config_json is not None`: use the edit's config
- If `edit_commit.generation_config_json is None`: keep the original commit's config (already in the snapshot)

### Pitfall 5: Cache Corruption From record_usage()

**What goes wrong:** `record_usage()` currently modifies the single `_compile_snapshot` to update token counts and token_source. With an LRU cache, it must update the correct entry. If the entry was already evicted, the update is lost.
**Why it happens:** `record_usage()` was designed for the single-snapshot model.
**How to avoid:** `record_usage()` should look up the snapshot by `target_hash` in the LRU cache. If found, create a new snapshot with updated token_count/token_source using `dataclasses.replace()` and store it back. If not found, trigger a compile first (current behavior already does this).

### Pitfall 6: batch() Must Clear Entire LRU Cache

**What goes wrong:** If batch() only clears the current HEAD's snapshot, stale entries for the same commit chain but different HEAD positions could produce wrong results after the batch modifies the chain.
**Why it happens:** batch() writes multiple commits atomically. Any cached snapshot whose chain overlaps with the batch commits is potentially stale.
**How to avoid:** `batch()` clears the entire LRU cache, same as the current behavior (`self._compile_snapshot = None` becomes `self._snapshot_cache.clear()`). This is the safe, simple approach. Selective invalidation is not worth the complexity.

## Code Examples

### LRU Cache with OrderedDict (verified stdlib pattern)

```python
# Source: collections.OrderedDict (Python stdlib documentation)
from collections import OrderedDict

class LRUCache:
    """Simple LRU cache using OrderedDict."""

    def __init__(self, maxsize: int = 8):
        self._cache: OrderedDict[str, object] = OrderedDict()
        self._maxsize = maxsize

    def get(self, key: str) -> object | None:
        if key not in self._cache:
            return None
        self._cache.move_to_end(key)
        return self._cache[key]

    def put(self, key: str, value: object) -> None:
        if key in self._cache:
            self._cache.move_to_end(key)
        self._cache[key] = value
        while len(self._cache) > self._maxsize:
            self._cache.popitem(last=False)

    def remove(self, key: str) -> None:
        self._cache.pop(key, None)

    def clear(self) -> None:
        self._cache.clear()

    def __len__(self) -> int:
        return len(self._cache)

    def __contains__(self, key: str) -> bool:
        return key in self._cache
```

### Frozen Dataclass Replacement (verified stdlib pattern)

```python
# Source: dataclasses.replace() (Python stdlib documentation)
from dataclasses import dataclass, replace

@dataclass(frozen=True)
class CompileSnapshot:
    head_hash: str
    raw_messages: tuple
    aggregated_messages: tuple
    effective_hashes: frozenset
    commit_count: int
    token_count: int
    token_source: str
    generation_configs: tuple = ()
    commit_hashes: tuple = ()  # NEW: parallel to raw_messages

# Create a patched copy with new head_hash and messages:
patched = replace(
    original_snapshot,
    head_hash=new_head_hash,
    raw_messages=tuple(new_raw),
    aggregated_messages=tuple(new_aggregated),
    token_count=new_token_count,
)
```

### Extended CompileSnapshot (new field)

```python
@dataclass(frozen=True)
class CompileSnapshot:
    """Cached intermediate compilation state for incremental extension.

    Stores both pre-aggregation and post-aggregation messages so that
    tail aggregation can be computed correctly when extending.
    """
    head_hash: str
    raw_messages: tuple[Message, ...]
    aggregated_messages: tuple[Message, ...]
    effective_hashes: frozenset[str]
    commit_count: int
    token_count: int
    token_source: str
    generation_configs: tuple[dict, ...] = ()
    commit_hashes: tuple[str, ...] = ()  # NEW: ordered commit hashes, parallel to raw_messages
```

### Oracle Test Pattern

```python
def test_edit_patching_matches_full_recompile():
    """Oracle test: patched result must be identical to fresh full recompile."""
    with Tract.open(":memory:", tract_id="oracle-test", verify_cache=True) as t:
        c1 = t.commit(InstructionContent(text="System prompt"))
        c2 = t.commit(DialogueContent(role="user", text="Original question"))
        c3 = t.commit(DialogueContent(role="assistant", text="Original answer"))
        t.compile()  # Populate cache

        # EDIT c2's content
        t.commit(
            DialogueContent(role="user", text="Edited question"),
            operation=CommitOperation.EDIT,
            response_to=c2.commit_hash,
        )

        # With verify_cache=True, this will internally assert patched == full recompile
        result = t.compile()
        assert "Edited question" in result.messages[1].content

    # Verify against a completely fresh instance
    with Tract.open(":memory:", tract_id="oracle-fresh") as t2:
        t2.commit(InstructionContent(text="System prompt"))
        c2b = t2.commit(DialogueContent(role="user", text="Original question"))
        t2.commit(DialogueContent(role="assistant", text="Original answer"))
        t2.commit(
            DialogueContent(role="user", text="Edited question"),
            operation=CommitOperation.EDIT,
            response_to=c2b.commit_hash,
        )
        fresh_result = t2.compile()

    assert result.messages == fresh_result.messages
    assert result.token_count == fresh_result.token_count
```

## State of the Art

| Old Approach (Phase 1.1) | New Approach (Phase 1.4) | Impact |
|---------------------------|--------------------------|--------|
| Single `CompileSnapshot` | LRU cache of snapshots | Checkout/reset/branch-switch get cache hits instead of full recompile |
| EDIT invalidates cache entirely | EDIT patches snapshot in-memory | Zero DB re-reads for EDIT commits |
| Annotate invalidates cache entirely | Annotate patches snapshot (SKIP case) | Avoids full recompile for common SKIP annotations |
| No commit hash tracking in snapshot | `commit_hashes` tuple parallel to `raw_messages` | Enables O(1) lookup of which message to patch |

**Deprecated/outdated:**
- `self._compile_snapshot: CompileSnapshot | None` -- replaced by `self._snapshot_cache: OrderedDict[str, CompileSnapshot]`
- Full cache invalidation on EDIT -- replaced by in-memory patching
- Full cache invalidation on annotate (SKIP) -- replaced by in-memory patching

## Design Decisions (Recommendations)

### LRU Cache Maxsize

**Recommendation: Default 8, configurable via `TractConfig`.**

Rationale: In the dominant use case (linear commit-then-compile loop), only 1 entry is needed. But checkout/reset scenarios benefit from caching prior positions. 8 is enough for typical exploration patterns (a few checkouts back and forth) without significant memory overhead. Each snapshot's memory is dominated by the message tuple, which is bounded by the context window size (typically 4K-128K tokens of text).

### Where to Put the LRU Cache

**Recommendation: On `Tract` instance, same location as current `_compile_snapshot`.**

The cache is per-Tract-instance, not global. This is correct because:
- Each Tract has its own session and DB connection
- Cache entries reference commit hashes that are scoped to a tract
- No thread safety concerns (Tract is documented as not thread-safe)
- GC is automatic (Tract.close() drops the instance, cache goes with it)

### Exposing verify_cache

**Recommendation: `verify_cache: bool = False` parameter on `Tract.open()` and `Tract.from_components()`.**

This flag enables oracle testing in production debug scenarios. When True, every cache hit/patch triggers a full recompile and asserts equality. It should NOT be True by default (doubles the work), but it's invaluable for testing and debugging cache consistency.

### EDIT Patching: What Information Is Needed

For EDIT patching to work, the snapshot must know which raw message corresponds to which commit. The current `CompileSnapshot` has `effective_hashes: frozenset[str]` which is unordered and cannot map to message positions.

**Recommendation: Add `commit_hashes: tuple[str, ...]` to `CompileSnapshot`.** This is an ordered tuple, parallel to `raw_messages`, where `commit_hashes[i]` is the commit that produced `raw_messages[i]`. This enables O(1) lookup of which message to replace for an EDIT.

### Annotate Patching Scope

**Recommendation: Patch only SKIP annotations (message removal). Un-skip falls back to full recompile.**

Rationale:
- SKIP is the common annotation change during active use ("I don't want this in context anymore")
- Un-skipping requires the original message content which is not stored in the snapshot when the commit was skipped
- Storing all messages (including skipped) adds complexity for a rare case
- Full recompile for un-skip is acceptable (it's a rare operation)

### What `_aggregate_messages` Access Pattern

The patching code needs to call `DefaultContextCompiler._aggregate_messages()` to re-aggregate after replacing/removing a message. This is currently a private method (underscore prefix).

**Recommendation: Keep it private but call it from Tract via `self._compiler._aggregate_messages()`.** This is acceptable because:
- Tract already has an `isinstance(self._compiler, DefaultContextCompiler)` check
- The alternative (making it public) pollutes the ContextCompiler protocol
- The alternative (duplicating aggregation logic) creates divergence risk
- Tract and DefaultContextCompiler are in the same package; this is internal coupling, not external

## Open Questions

1. **Should the LRU cache maxsize be in TractConfig?**
   - What we know: It's an implementation detail, not a user-facing feature. But power users tuning performance may want to adjust it.
   - What's unclear: Whether the config should be public API or an internal-only knob.
   - Recommendation: Add it to TractConfig with a default of 8. Low cost, high flexibility. Document as "advanced/internal."

2. **What about `record_usage()` interaction with LRU?**
   - What we know: `record_usage()` updates token_count and token_source on the current snapshot. With LRU, it needs to update the correct entry.
   - What's unclear: If the snapshot was evicted between compile() and record_usage(), the update is lost.
   - Recommendation: `record_usage()` looks up by `target_hash` in LRU. If missing, triggers compile() to repopulate (current behavior). The `replace()` pattern creates a new snapshot with updated fields and stores it back.

3. **Should annotate patching handle un-skip?**
   - What we know: Un-skipping requires the original message content, which is not in the snapshot.
   - Recommendation: Phase 1.4 only patches for SKIP (removal). Un-skip falls back to full recompile. If un-skip proves to be a performance bottleneck in future phases, revisit by storing all messages with a skip mask.

## Sources

### Primary (HIGH confidence)
- **Codebase inspection** - `src/tract/tract.py` (current single-snapshot cache), `src/tract/protocols.py` (CompileSnapshot definition), `src/tract/engine/compiler.py` (DefaultContextCompiler full compile flow)
- **Phase 1.1 Plan** - `.planning/phases/01.1-compile-cache-token-tracking/01.1-01-PLAN.md` (original cache design rationale)
- **Python stdlib docs** - `collections.OrderedDict.move_to_end()`, `dataclasses.replace()`

### Secondary (MEDIUM confidence)
- [LRU Cache in Python using OrderedDict - GeeksforGeeks](https://www.geeksforgeeks.org/python/lru-cache-in-python-using-ordereddict/) - Confirmed OrderedDict LRU pattern
- [Don't wrap instance methods with functools.lru_cache - Rednafi](https://rednafi.com/python/lru-cache-on-methods/) - Confirmed lru_cache anti-pattern for methods
- [Ruff B019: cached-instance-method](https://docs.astral.sh/ruff/rules/cached-instance-method/) - Confirmed lru_cache on methods is a lint warning
- [dataclasses.replace() for frozen dataclass modification](https://elshad-karimov.medium.com/pythons-dataclasses-replace-a-hidden-gem-for-immutable-data-handling-e10a82f6260b) - Confirmed replace() is idiomatic
- [Test Oracle - Wikipedia](https://en.wikipedia.org/wiki/Test_oracle) - Reference implementation oracle testing pattern

### Tertiary (LOW confidence)
- None. All findings are based on codebase inspection and well-established Python patterns.

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - All stdlib, well-established patterns, no external dependencies
- Architecture: HIGH - Based on thorough codebase inspection; all modifications are in 2 files (protocols.py, tract.py)
- Pitfalls: HIGH - Derived from direct analysis of existing CompileSnapshot limitations and edge cases in the compiler
- Code examples: HIGH - Based on existing codebase patterns extended with stdlib primitives

**Research date:** 2026-02-11
**Valid until:** Indefinite (stdlib patterns, internal codebase refactor)
