---
phase: 01.1-compile-cache-token-tracking
verified: 2026-02-11T03:39:33Z
status: passed
score: 19/19 must-haves verified
re_verification: false
---

# Phase 1.1: Incremental Compile Cache & Token Tracking Verification Report

**Phase Goal:** Reduce compile latency via incremental caching for append-only operations, and establish API-reported token usage as the primary source of truth over tiktoken estimates

**Verified:** 2026-02-11T03:39:33Z

**Status:** PASSED

**Re-verification:** No â€” initial verification

## Goal Achievement

### Observable Truths

| # | Truth | Status | Evidence |
|---|-------|--------|----------|
| 1 | Compiling after an APPEND commit reuses cached intermediate state, not O(n) full chain walk | VERIFIED | _extend_snapshot_for_append() exists, calls build_message_for_commit() for single commit |
| 2 | EDIT commits trigger full cache invalidation, not incremental extension | VERIFIED | Line 290 in repo.py sets _compile_snapshot = None when operation != APPEND |
| 3 | annotate() calls trigger full cache invalidation | VERIFIED | Line 361 in repo.py: annotate() sets _compile_snapshot = None |
| 4 | batch() invalidates cache on entry | VERIFIED | Line 512 in repo.py: _compile_snapshot = None at batch entry |
| 5 | Custom compilers bypass incremental cache entirely | VERIFIED | Lines 283-287: incremental only for DefaultContextCompiler |
| 6 | Time-travel params bypass cache and do full compile | VERIFIED | Lines 316-323: time-travel params bypass snapshot entirely |
| 7 | Incremental extend produces identical output to full compile | VERIFIED | test_append_fast_path_matches_full_compile proves equivalence |
| 8 | User can call record_usage() with OpenAI-format dict | VERIFIED | _normalize_usage_dict() handles OpenAI format |
| 9 | User can call record_usage() with Anthropic-format dict | VERIFIED | Lines 485-492 handle Anthropic format |
| 10 | User can call record_usage() with TokenUsage dataclass | VERIFIED | Lines 428-431 accept TokenUsage type |
| 11 | token_source reflects api:N+M format after record_usage() | VERIFIED | Line 450: token_source = f"api:{usage.prompt_tokens}+{usage.completion_tokens}" |
| 12 | Subsequent compile() returns API-reported counts | VERIFIED | Lines 449-460 update snapshot with API counts |
| 13 | record_usage() raises TraceError when no commits exist | VERIFIED | Lines 434-435: raises TraceError if target_hash is None |
| 14 | record_usage() raises ContentValidationError for bad format | VERIFIED | Lines 493-498 in _normalize_usage_dict() |

**Score:** 14/14 truths from plans verified

### Phase Success Criteria (from ROADMAP.md)

| # | Criterion | Status | Evidence |
|---|-----------|--------|----------|
| 1 | APPEND reuses cached state (O(1) not O(n)) | VERIFIED | Incremental path implementation complete |
| 2 | EDIT and annotate trigger invalidation | VERIFIED | Invalidation confirmed in code and tests |
| 3 | User can feed API-reported usage via record_usage() | VERIFIED | record_usage() API complete, all formats supported |
| 4 | tiktoken pre-call, API actuals post-call | VERIFIED | test_full_workflow_tiktoken_then_api proves two-tier flow |
| 5 | token_source accurately reflects count source | VERIFIED | Format: tiktoken:{encoding} or api:{prompt}+{completion} |

**Score:** 5/5 phase success criteria verified

### Required Artifacts

| Artifact | Status | Details |
|----------|--------|---------|
| src/tract/protocols.py CompileSnapshot | VERIFIED | Line 40-53: class CompileSnapshot with 7 fields |
| src/tract/engine/compiler.py build_message_for_commit | VERIFIED | Line 235-256: public method |
| src/tract/repo.py _compile_snapshot | VERIFIED | Line 89: field declaration |
| src/tract/repo.py incremental logic | VERIFIED | Lines 283-290, 325-332, 577-623 |
| src/tract/repo.py record_usage | VERIFIED | Lines 400-469: complete implementation |
| src/tract/repo.py _normalize_usage_dict | VERIFIED | Lines 471-498: OpenAI and Anthropic formats |
| tests/test_repo.py test_incremental | VERIFIED | Lines 609-796: 7 tests |
| tests/test_repo.py test_record_usage | VERIFIED | Lines 803-1038: 13 tests |

**Score:** 8/8 artifacts verified

### Key Links

| From | To | Via | Status |
|------|-----|-----|--------|
| repo.py | protocols.py | CompileSnapshot import | WIRED |
| repo.py | compiler.py | build_message_for_commit() call | WIRED |
| repo.py | protocols.py | TokenUsage import | WIRED |
| tests | repo.py | Incremental cache tests | WIRED |
| tests | repo.py | record_usage tests | WIRED |

**Score:** 5/5 key links verified

### Anti-Patterns

No anti-patterns found. Scan results:
- No TODO/FIXME/XXX/HACK/placeholder comments
- No stub implementations
- All methods have substantive implementations

### Test Results

**Total tests:** 220 (all PASSED in 2.19s)

**New tests in Phase 1.1:** 20 tests
- TestIncrementalCompileCache: 7 tests
- TestRecordUsage: 9 tests
- TestTwoTierTokenTracking: 4 tests

**Regression check:** All 200 Phase 1 tests continue to pass

### Requirements Coverage

| Requirement | Status | Evidence |
|-------------|--------|----------|
| CORE-09 (token tracking) | SATISFIED | Two-tier token tracking implemented |
| INFR-06 (performance) | SATISFIED | O(1) incremental cache for APPEND paths |

---

## Verification Summary

**Overall Assessment:** Phase 1.1 goal FULLY ACHIEVED

**Evidence:**
1. Incremental compile cache works (O(1) APPEND, proper invalidation)
2. Two-tier token tracking via record_usage() complete
3. Token source provenance accurate
4. 20 new tests, 220 total passing, no regressions
5. No anti-patterns or incomplete implementations

**All must-haves verified:** 19/19 (14 truths + 5 success criteria)

**Ready to proceed:** Phase 2 (Linear History & CLI)

---

_Verified: 2026-02-11T03:39:33Z_
_Verifier: Claude (gsd-verifier)_
