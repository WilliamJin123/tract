# Phase 1.1 Plan 02: record_usage() API Summary

**One-liner:** Two-tier token tracking via record_usage() accepting OpenAI/Anthropic/TokenUsage formats, updating CompileSnapshot with API-reported counts and correct tiktoken reset on new commits.

## Tasks Completed

| Task | Name | Commits | Tests |
|------|------|---------|-------|
| 1 | record_usage() with TDD (RED + GREEN) | c159a54, e8edbb0 | 9 |
| 2 | End-to-end two-tier integration tests | 80efeb3 | 4 |

## What Was Built

### record_usage() Method
- Accepts `TokenUsage` dataclass, OpenAI-format dict (`prompt_tokens`/`completion_tokens`/`total_tokens`), or Anthropic-format dict (`input_tokens`/`output_tokens`)
- Updates `_compile_snapshot` with API-reported token count and source string
- Auto-triggers compile if no snapshot exists (no prior compile needed)
- Validates `head_hash` against current HEAD when explicitly provided
- Raises `TraceError` if no commits exist, `ContentValidationError` for unrecognized dict formats

### _normalize_usage_dict() Helper
- Converts OpenAI and Anthropic provider-specific dicts to `TokenUsage` dataclass
- OpenAI: `prompt_tokens` -> `prompt_tokens`, `completion_tokens` -> `completion_tokens`
- Anthropic: `input_tokens` -> `prompt_tokens`, `output_tokens` -> `completion_tokens`, auto-computes total

### _tiktoken_source() Helper
- Returns `tiktoken:{encoding_name}` string for TiktokenCounter instances
- Used by `_extend_snapshot_for_append()` to reset token_source after API recording

### Token Source Transitions
- Pre-call: `"tiktoken:o200k_base"` (or whatever encoding is configured)
- Post-call: `"api:{prompt}+{completion}"` after `record_usage()`
- New commit: Resets back to `"tiktoken:..."` via incremental extension recount

## Deviations from Plan

### Auto-fixed Issues

**1. [Rule 1 - Bug] _extend_snapshot_for_append carried forward stale token_source**

- **Found during:** Task 1 GREEN phase (test 9 failure)
- **Issue:** `_extend_snapshot_for_append()` copied `snapshot.token_source` verbatim, so after `record_usage()` set it to "api:...", a new APPEND commit would still show "api:..." even though tokens were recounted by tiktoken
- **Fix:** Added `_tiktoken_source()` helper method; `_extend_snapshot_for_append()` now always sets `token_source=self._tiktoken_source()` since it always recounts with tiktoken
- **Files modified:** `src/tract/repo.py`
- **Commit:** e8edbb0

## Decisions Made

- record_usage() validates head_hash match BEFORE attempting compile (fail-fast)
- record_usage() auto-compiles if no snapshot exists (user doesn't need to call compile() first)
- Token source format standardized: `"tiktoken:{encoding}"` and `"api:{prompt}+{completion}"`

## Test Summary

| Category | Count |
|----------|-------|
| New record_usage tests | 9 |
| New integration tests | 4 |
| Total new tests | 13 |
| Total suite | 220 |
| Regressions | 0 |

## Key Files

### Created
None (all modifications to existing files)

### Modified
- `src/tract/repo.py` -- record_usage(), _normalize_usage_dict(), _tiktoken_source()
- `tests/test_repo.py` -- TestRecordUsage (9 tests), TestTwoTierTokenTracking (4 tests)

## Phase 1.1 Completion Status

Both plans in Phase 1.1 are now complete:

| Plan | Name | Tests | Duration |
|------|------|-------|----------|
| 01.1-01 | Incremental Compile Cache | 7 | 3m |
| 01.1-02 | record_usage() API | 13 | 3m |
| **Total** | | **20** | **6m** |

Phase 1.1 adds 20 tests to the suite (207 -> 220 total after both plans minus the 7 from plan 01).

## Next Phase Readiness

Phase 1.1 is complete. The compile cache and two-tier token tracking provide:
- O(1) APPEND-only compile via incremental snapshot extension
- API-reported token counts override tiktoken estimates post-call
- Clean token_source provenance tracking for debugging/observability

Ready to proceed to Phase 2 (Linear History).
