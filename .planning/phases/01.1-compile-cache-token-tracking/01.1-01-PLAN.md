---
phase: 01.1-compile-cache-token-tracking
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/tract/protocols.py
  - src/tract/engine/compiler.py
  - src/tract/repo.py
  - tests/test_engine/test_compiler.py
  - tests/test_repo.py
autonomous: true

must_haves:
  truths:
    - "Compiling after an APPEND commit reuses cached intermediate state, not O(n) full chain walk"
    - "EDIT commits trigger full cache invalidation, not incremental extension"
    - "annotate() calls trigger full cache invalidation"
    - "batch() invalidates cache on entry; first compile after batch rebuilds from scratch"
    - "Custom compilers bypass incremental cache entirely (always full compile)"
    - "Time-travel params (as_of, up_to) bypass cache and do full compile"
    - "Incremental extend produces identical output to full compile for same input"
  artifacts:
    - path: "src/tract/protocols.py"
      provides: "CompileSnapshot frozen dataclass"
      contains: "class CompileSnapshot"
    - path: "src/tract/engine/compiler.py"
      provides: "build_message_for_commit() helper extracted from _build_messages"
      contains: "def build_message_for_commit"
    - path: "src/tract/repo.py"
      provides: "Incremental compile logic with _compile_snapshot field"
      contains: "_compile_snapshot"
    - path: "tests/test_repo.py"
      provides: "Tests for incremental cache behavior"
      contains: "test_incremental"
  key_links:
    - from: "src/tract/repo.py"
      to: "src/tract/protocols.py"
      via: "CompileSnapshot import and usage"
      pattern: "CompileSnapshot"
    - from: "src/tract/repo.py"
      to: "src/tract/engine/compiler.py"
      via: "build_message_for_commit() delegation"
      pattern: "build_message_for_commit"
---

<objective>
Implement an incremental compile cache that makes APPEND-only compile paths O(1) instead of O(n), using a CompileSnapshot frozen dataclass to store intermediate compilation state.

Purpose: The dominant usage pattern is commit-then-compile in a loop. Currently every compile walks the entire chain. After this plan, APPEND commits extend the cached snapshot incrementally (build one message, tail-aggregate, recount tokens) while EDIT/annotate/batch operations correctly invalidate and force full recompile.

Output: CompileSnapshot dataclass, extracted message-building helper in compiler, incremental extend logic in Repo, comprehensive tests proving equivalence between incremental and full compile paths.
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01.1-compile-cache-token-tracking/01.1-RESEARCH.md
@tutorials/01.1-incremental-compile-cache-and-token-tracking.md
@src/tract/protocols.py
@src/tract/engine/compiler.py
@src/tract/repo.py
@src/tract/__init__.py
@tests/test_repo.py
@tests/test_engine/test_compiler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CompileSnapshot dataclass and extract build_message_for_commit helper</name>
  <files>
    src/tract/protocols.py
    src/tract/engine/compiler.py
    src/tract/__init__.py
  </files>
  <action>
    **1a. Add CompileSnapshot to protocols.py:**

    Add a new frozen dataclass after CompiledContext:

    ```python
    @dataclass(frozen=True)
    class CompileSnapshot:
        """Cached intermediate compilation state for incremental extension.

        Stores both pre-aggregation and post-aggregation messages so that
        tail aggregation can be computed correctly when extending.
        """
        head_hash: str
        raw_messages: tuple[Message, ...]
        aggregated_messages: tuple[Message, ...]
        effective_hashes: frozenset[str]
        commit_count: int
        token_count: int
        token_source: str
    ```

    Add `CompileSnapshot` to `__init__.py` exports and `__all__`.

    **1b. Extract build_message_for_commit() from DefaultContextCompiler:**

    In `engine/compiler.py`, extract a public helper method from the existing `_build_messages()` loop body. This method takes a single CommitRow (the "source commit" after edit resolution) and returns a Message:

    ```python
    def build_message_for_commit(self, commit_row: CommitRow) -> Message:
        """Build a single Message from a commit's blob content.

        Loads the blob, parses JSON, maps content_type to role,
        extracts text. This is the single-commit equivalent of the
        loop body in _build_messages().

        Returns:
            Message with role, content, and optional name.
        """
        blob = self._blob_repo.get(commit_row.content_hash)
        if blob is None:
            logger.warning("Blob not found for commit %s", commit_row.commit_hash)
            return Message(role="system", content="[missing content]")

        content_data = json.loads(blob.payload_json)
        content_type = content_data.get("content_type", "unknown")
        role = self._map_role(content_type, content_data)
        text = self._extract_message_text(content_type, content_data)
        name = content_data.get("name") if content_type == "dialogue" else None
        return Message(role=role, content=text, name=name)
    ```

    Then refactor `_build_messages()` to call `build_message_for_commit()` internally, preserving the edit_map lookup and annotation logic in the caller. The edit resolution (choosing source_commit from edit_map) stays in `_build_messages()`. The method signature is:

    ```python
    def _build_messages(self, effective_commits, edit_map, include_edit_annotations):
        messages = []
        for c in effective_commits:
            source_commit = edit_map.get(c.commit_hash, c)
            msg = self.build_message_for_commit(source_commit)
            if include_edit_annotations and c.commit_hash in edit_map:
                msg = Message(role=msg.role, content=msg.content + " [edited]", name=msg.name)
            messages.append(msg)
        return messages
    ```

    This is a pure refactor -- no behavioral change. Existing tests must still pass.
  </action>
  <verify>
    Run: `python -m pytest tests/test_engine/test_compiler.py -v`
    All existing compiler tests pass (no behavioral change from the refactor).
    Verify `CompileSnapshot` is importable: `python -c "from tract.protocols import CompileSnapshot; print('OK')"`
  </verify>
  <done>
    CompileSnapshot dataclass exists in protocols.py. build_message_for_commit() is a public method on DefaultContextCompiler. _build_messages() delegates to it. All existing compiler tests pass unchanged.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement incremental compile cache in Repo with TDD</name>
  <files>
    src/tract/repo.py
    tests/test_repo.py
  </files>
  <action>
    **RED phase -- Write failing tests first:**

    Add a new test class `TestIncrementalCompileCache` in `tests/test_repo.py` with these test cases:

    1. `test_append_fast_path_matches_full_compile` -- Commit 5 APPEND items, compile. Then commit 1 more APPEND, compile again. Assert the second compile's output is identical to a fresh full compile (open a second repo on the same DB and compile from scratch). This proves incremental == full.

    2. `test_append_same_role_aggregation` -- Commit 3 consecutive DialogueContent(role="user") messages (all APPEND). Compile after each one. Assert the final compile has 1 aggregated user message (content joined with "\n\n"). Compare against full compile.

    3. `test_edit_invalidates_cache` -- Commit A (APPEND), compile (populates snapshot). Then commit B (EDIT of A). Compile again. Assert the compiled output reflects B's content, not A's. Assert `_compile_snapshot` was invalidated (set to None after EDIT commit).

    4. `test_annotate_invalidates_cache` -- Commit A, B, C (all APPEND). Compile (populates snapshot). Annotate B with SKIP. Compile again. Assert B's content is absent. This proves annotate invalidation works.

    5. `test_batch_invalidates_and_rebuilds` -- Enter batch(), commit 3 items, exit batch. Compile. Assert output matches full compile of the 3 items. Assert that inside the batch, no incremental extension occurred (snapshot was None during batch).

    6. `test_time_travel_bypasses_cache` -- Commit A, B, C. Compile (populates snapshot). Then compile with `up_to=A.commit_hash`. Assert result only contains A's content. Assert the cached snapshot is still for the full HEAD (time-travel didn't overwrite it).

    7. `test_custom_compiler_bypasses_incremental` -- Create a repo with `compiler=custom_compiler` (a simple mock that returns fixed output). Commit twice, compile each time. Assert the custom compiler's `compile()` was called each time (no caching bypass).

    **GREEN phase -- Implement incremental cache in Repo:**

    In `repo.py`, replace `_compile_cache: dict[str, CompiledContext]` with `_compile_snapshot: CompileSnapshot | None = None`.

    Key changes to `Repo.__init__()`:
    - Remove `self._compile_cache: dict[str, CompiledContext] = {}`
    - Add `self._compile_snapshot: CompileSnapshot | None = None`

    Modify `Repo.commit()`:
    - After commit succeeds, check if we can do incremental extension:
      - If `operation == CommitOperation.APPEND` AND `self._compile_snapshot is not None` AND `isinstance(self._compiler, DefaultContextCompiler)`:
        Call `self._extend_snapshot_for_append(info)` to create a new snapshot
      - Otherwise: set `self._compile_snapshot = None` (invalidate)

    Modify `Repo.compile()`:
    ```python
    def compile(self, *, as_of=None, up_to=None, include_edit_annotations=False):
        current_head = self.head
        if current_head is None:
            return CompiledContext(messages=[], token_count=0, commit_count=0, token_source="")

        # Time-travel and edit annotations: always full compile, don't touch snapshot
        if as_of is not None or up_to is not None or include_edit_annotations:
            return self._compiler.compile(
                self._repo_id, current_head,
                as_of=as_of, up_to=up_to,
                include_edit_annotations=include_edit_annotations,
            )

        # Cache hit: snapshot exists for current head
        if self._compile_snapshot is not None and self._compile_snapshot.head_hash == current_head:
            return self._snapshot_to_compiled(self._compile_snapshot)

        # Cache miss: full compile and build snapshot
        result = self._compiler.compile(self._repo_id, current_head)
        self._compile_snapshot = self._build_snapshot_from_compiled(current_head, result)
        return result
    ```

    Add helper methods to Repo:

    ```python
    def _snapshot_to_compiled(self, snapshot: CompileSnapshot) -> CompiledContext:
        """Convert a CompileSnapshot to a CompiledContext for return."""
        return CompiledContext(
            messages=list(snapshot.aggregated_messages),
            token_count=snapshot.token_count,
            commit_count=snapshot.commit_count,
            token_source=snapshot.token_source,
        )

    def _build_snapshot_from_compiled(self, head_hash: str, result: CompiledContext) -> CompileSnapshot | None:
        """Build a CompileSnapshot from a full compile result.

        NOTE: raw_messages is set to the same as aggregated_messages since we
        don't have pre-aggregation data from a full compile. This means the
        first incremental extension after a full compile must handle the case
        where raw_messages == aggregated_messages. For tail aggregation, we
        only need the last aggregated message's role, which is available.
        """
        if not isinstance(self._compiler, DefaultContextCompiler):
            return None
        return CompileSnapshot(
            head_hash=head_hash,
            raw_messages=tuple(result.messages),  # Use aggregated as raw (approximate)
            aggregated_messages=tuple(result.messages),
            effective_hashes=frozenset(),  # Not tracked from full compile
            commit_count=result.commit_count,
            token_count=result.token_count,
            token_source=result.token_source,
        )

    def _extend_snapshot_for_append(self, commit_info: CommitInfo) -> None:
        """Extend the cached snapshot for a single APPEND commit.

        Builds the new commit's message using the compiler's
        build_message_for_commit() helper, then performs tail aggregation
        and token recount.
        """
        snapshot = self._compile_snapshot
        if snapshot is None:
            return  # Nothing to extend

        # Get the CommitRow for the new commit
        commit_row = self._commit_repo.get(commit_info.commit_hash)
        if commit_row is None:
            self._compile_snapshot = None  # Safety: invalidate
            return

        # Build message for the new commit
        assert isinstance(self._compiler, DefaultContextCompiler)
        new_message = self._compiler.build_message_for_commit(commit_row)

        # Extend raw messages
        new_raw = snapshot.raw_messages + (new_message,)

        # Tail aggregation
        if snapshot.aggregated_messages and new_message.role == snapshot.aggregated_messages[-1].role:
            last = snapshot.aggregated_messages[-1]
            merged = Message(
                role=last.role,
                content=last.content + "\n\n" + new_message.content,
                name=last.name,
            )
            new_aggregated = snapshot.aggregated_messages[:-1] + (merged,)
        else:
            new_aggregated = snapshot.aggregated_messages + (new_message,)

        # Recount tokens on aggregated messages
        messages_dicts = [
            {"role": m.role, "content": m.content}
            if m.name is None
            else {"role": m.role, "content": m.content, "name": m.name}
            for m in new_aggregated
        ]
        new_token_count = self._token_counter.count_messages(messages_dicts)

        self._compile_snapshot = CompileSnapshot(
            head_hash=commit_info.commit_hash,
            raw_messages=new_raw,
            aggregated_messages=new_aggregated,
            effective_hashes=snapshot.effective_hashes | {commit_info.commit_hash},
            commit_count=snapshot.commit_count + 1,
            token_count=new_token_count,
            token_source=snapshot.token_source,
        )
    ```

    Modify `Repo.annotate()`:
    - Replace `self._compile_cache.clear()` with `self._compile_snapshot = None`

    Modify `Repo.batch()`:
    - At the start (before yield): `self._compile_snapshot = None`
    - The existing `_compile_cache.clear()` calls inside `commit()` are now `self._compile_snapshot = None`, which is fine during batch.

    Import `CompileSnapshot` and `Message` from `tract.protocols` in `repo.py`.

    **REFACTOR phase:**

    Clean up any duplication. Ensure the `_compile_cache` dict is fully removed from `__init__` and all references.
  </action>
  <verify>
    Run: `python -m pytest tests/test_repo.py -v`
    All existing tests pass + all 7 new incremental cache tests pass.
    Run: `python -m pytest tests/ -v` for full suite regression check.
  </verify>
  <done>
    Incremental compile cache works for APPEND operations. EDIT/annotate/batch/time-travel/custom-compiler all correctly invalidate or bypass. Every test proves incremental == full compile equivalence.
  </done>
</task>

</tasks>

<verification>
Run the full test suite to ensure no regressions:

```bash
python -m pytest tests/ -v
```

Expected: All existing 200 tests pass + 7 new incremental cache tests pass.

Manual smoke test:
```python
from tract import Repo, DialogueContent, InstructionContent
repo = Repo.open()
repo.commit(InstructionContent(text="You are helpful."))
ctx1 = repo.compile()
repo.commit(DialogueContent(role="user", text="Hi"))
ctx2 = repo.compile()  # Should use incremental fast path
print(f"Messages: {len(ctx2.messages)}, Tokens: {ctx2.token_count}")
print(f"Snapshot head: {repo._compile_snapshot.head_hash}")
```
</verification>

<success_criteria>
1. CompileSnapshot dataclass in protocols.py, importable from tract
2. build_message_for_commit() is a public method on DefaultContextCompiler
3. APPEND commits extend the snapshot incrementally (O(1))
4. EDIT commits invalidate the snapshot
5. annotate() invalidates the snapshot
6. batch() invalidates on entry, rebuilds after
7. Time-travel params bypass cache without overwriting snapshot
8. Custom compilers bypass incremental cache entirely
9. All 200+ tests pass with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/01.1-compile-cache-token-tracking/01.1-01-SUMMARY.md`
</output>
